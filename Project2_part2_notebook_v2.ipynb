{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>LINMA2472 : Project 2 - part 2, Random Fourier Features </center></h1>\n",
    "\n",
    "$\\textbf{Author}$: Remi Delogne, remi.delogne@uclouvain.be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the following packages and functions. Refer to their documentation on the internet for more information on installation and usage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets, svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from keras.datasets import mnist #Contains the dataset\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import time #Used to find the execution time of a part of the code\n",
    "\n",
    "from IPython.display import display, HTML #For visual comfort\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset and rescale the data to [0,15]\n",
    "''' load dataset: (we use the larger subset for testing and the smaller \n",
    "for training to demonstrate the efficiency of evaluating of new instances with RFF)'''\n",
    "(testX,testy),(trainX,trainy) = mnist.load_data()\n",
    "#Rescaling\n",
    "trainX = np.floor(trainX/16)\n",
    "testX = np.floor(testX/16)\n",
    "\n",
    "#Plot some images, for fun\n",
    "for i in range(9):\n",
    "    pyplot.subplot(330+1+i)\n",
    "    pyplot.imshow(trainX[i], cmap=pyplot.get_cmap('gray'))\n",
    "pyplot.show()\n",
    "\n",
    "#Put the data in vector form\n",
    "trainX=trainX.reshape((10000,-1))\n",
    "testX=testX.reshape((60000,-1))\n",
    "print(trainX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the *time* package functions to time the executions of parts of your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example of timing a piece of code\n",
    "tik=time.perf_counter() # Start\n",
    "for i in range (1000000):\n",
    "    i=i+1\n",
    "tok=time.perf_counter() # Finish\n",
    "print(f'Total time: {tok-tik:.3f} seconds')#prints the result to 3 decimal places"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a linear SVM on the training data and evaluate it on the testing data\n",
    "Use the tik-tok method to see how long the classifier takes to evaluate the 60.000 testing instances.\n",
    "\n",
    "Use the accuracy metric to judge the quality of your classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the classifier\n",
    "clfLin=svm.SVC(kernel=\"linear\")\n",
    "\n",
    "#Train the classifier\n",
    "tik = time.perf_counter() # Start measuring training time\n",
    "clfLin.fit(trainX,trainy)\n",
    "tok = time.perf_counter() # Stop measuring training time\n",
    "linear_training_time = tok - tik\n",
    "\n",
    "#Evaluate its accuracy\n",
    "tik = time.perf_counter()\n",
    "predicted=clfLin.predict(testX)\n",
    "score_linear=accuracy_score(testy,predicted)\n",
    "tok = time.perf_counter()\n",
    "linear_testing_time = tok - tik\n",
    "\n",
    "print(f\"Training finished in {linear_training_time:.3f} seconds,\")\n",
    "print(f\"Testing Finished in {linear_testing_time:.3f} seconds with accuracy of {score_linear:.3f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Kernel SVM with the Gaussian Kernel on the training data and evaluate it on the testing data\n",
    "Use the tik-tok method to see how long the classifier takes to evaluate the $60000$ testing instances.\n",
    "\n",
    "Use the accuracy metric to judge the quality of your classifier.\n",
    "\n",
    "You may stick to the default parameters of sci-kit learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the classifier\n",
    "clfKernel=svm.SVC(kernel='rbf')\n",
    "#Train it\n",
    "tik = time.perf_counter()\n",
    "clfKernel.fit(trainX, trainy)\n",
    "tok = time.perf_counter()\n",
    "rbf_training_time = tok - tik\n",
    "\n",
    "#Use it\n",
    "tik = time.perf_counter()\n",
    "predicted=clfKernel.predict(testX)\n",
    "score_rbf=accuracy_score(testy,predicted)\n",
    "tok = time.perf_counter()\n",
    "rbf_testing_time = tok - tik\n",
    "\n",
    "print(f\"Training finished in {rbf_training_time:.3f} seconds,\")\n",
    "print(f\"Testing Finished in {rbf_testing_time:.3f} seconds with accuracy of {score_rbf:.3f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *TO DO*: Use the following functions to implement Random Fourier Features\n",
    "\n",
    "You are here going to try to approximate the Gaussian kernel used in the second classfier.\n",
    "\n",
    "Use the first function to generate your $\\boldsymbol\\omega_i$ (using an appropriate distribution) and your $b_i$ (using appropriate distributions), this should return $D$ vectors $\\boldsymbol\\omega_i\\in\\mathbb R^d$ (in the form of a matrix for example) and $D$ values $b_i\\in[0,2\\pi]$. \n",
    "\n",
    "Use the second function to create the mapping $\\boldsymbol z(\\boldsymbol x)$ as described in the slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_freq(...):\n",
    "  ...\n",
    "  return W,b\n",
    "\n",
    "def transform(...):\n",
    "  ...\n",
    "  return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *TO DO*: Transform your trainX and testX\n",
    "\n",
    "Use the function you defined to transform your data.\n",
    "\n",
    "Make sure you only generate $\\boldsymbol W$ and $\\boldsymbol b$ once.\n",
    "\n",
    "Use a standard deviation of $\\frac{1}{100}$ et $D=300$ random features to start with. Watch out, in the original version of the homework it was specified that the variance was $\\frac{1}{100}$ but it must be the standard deviation instead.\n",
    "\n",
    "You may also use the tik-tok method to time the procedure of creating Random features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D=300 #Number of sample vectors w_i\n",
    "sigma=0.01 #Variance of distributon\n",
    "d=28*28 #Original number of dimensions\n",
    "\n",
    "tik = time.perf_counter()\n",
    "W,b=generate_freq(...)\n",
    "trainX_rff=transform(...)\n",
    "testX_rff=transform(...)\n",
    "tok = time.perf_counter()\n",
    "rff_time = tok - tik\n",
    "print(f\"RFF transformation time : {rff_time:.3f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity check, do the dimensions of your transformations match your expectation?\n",
    "#Bear in mind that there are more instances in the test set than in the trianing set here\n",
    "print(f\"Dimension of trainX after transformation : {trainX_rff.shape}.\")\n",
    "print(f\"Dimension of testX after transformation : {testX_rff.shape}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use another linear SVM to classify the transformed data\n",
    "Now that the instances have been transformed, theory tells us that they are much more ameneable to linear classification than before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the classifier\n",
    "clfRff = svm.SVC(kernel=\"linear\",C=np.inf)\n",
    "\n",
    "#Train it\n",
    "tik = time.perf_counter()\n",
    "clfRff.fit(trainX_rff, trainy)\n",
    "tok = time.perf_counter() \n",
    "training_time_rff = tok - tik\n",
    "print(f\"Training Finished in {training_time_rff:.3f} seconds\")\n",
    "\n",
    "#Use it\n",
    "tik = time.perf_counter()\n",
    "predicted = clfRff.predict(testX_rff)\n",
    "score_rff = accuracy_score(testy,predicted)\n",
    "tok = time.perf_counter()\n",
    "testing_time_rff = tok - tik\n",
    "print(f\"Testing Finished in {testing_time_rff:.3f} seconds with accuracy of {score_rff:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional workspace "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate the relationship between $D$ and the accuracy of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a vector to store the accuracy values you will get\n",
    "accuracy=np.zeros()\n",
    "#Define for which values of D you want to test the RFF\n",
    "#maybe time some operations in the loop as well to see the RFF classifier becomes too slow as D grows\n",
    "for i in (...):\n",
    "    D=...\n",
    "    trainX_rff=...\n",
    "    testX_rff=...\n",
    "    \n",
    "    #Train and evaluate a linear classifier\n",
    "    \n",
    "    acc=...\n",
    "    accuracy[i]=acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Don't forget to add plots and other nice things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good luck =D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
